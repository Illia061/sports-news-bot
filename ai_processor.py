import os
import requests
from typing import Dict, Any
from urllib.parse import urlparse
import google.generativeai as genai
import time
from bs4 import BeautifulSoup
import logging
import random

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
CONFIG = {
    'CONTENT_MAX_LENGTH': 2000,
    'TELEGRAM_MESSAGE_LIMIT': 4000,  # –õ–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏—è Telegram
    'TELEGRAM_CAPTION_LIMIT': 1000,  # –õ–∏–º–∏—Ç –ø–æ–¥–ø–∏—Å–∏ –∫ —Ñ–æ—Ç–æ
    'SUMMARY_MAX_WORDS': 100,        # –£–º–µ–Ω—å—à–∏–ª–∏ –ª–∏–º–∏—Ç —Å–ª–æ–≤ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
    'USER_AGENTS': [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0'
    ]
}

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_AVAILABLE = False
model = None

def init_gemini():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞ Gemini."""
    global GEMINI_AVAILABLE, model
    if GEMINI_AVAILABLE:  # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return
    if not GEMINI_API_KEY:
        logger.warning("GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω - AI —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        return
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-2.5-flash")
        GEMINI_AVAILABLE = True
        logger.info("Gemini –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini: {e}")

def has_gemini_key() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–∞ Gemini –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ."""
    if not GEMINI_AVAILABLE:
        init_gemini()
    return GEMINI_AVAILABLE

def fetch_full_article_content(url: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ URL."""
    try:
        headers = {'User-Agent': random.choice(CONFIG['USER_AGENTS'])}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        content_selectors = (
            [
                '.RichTextStoryBody', '.Story__Body', '.ArticleBody',
                '[data-module="ArticleBody"]', '.story-body', '.article-body'
            ] if 'espn.com' in url else
            [
                # OneFootball —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                '[data-testid="article-body"]', '.ArticleBody',
                # –û–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                '.article-content', '.post-content', '.entry-content',
                '[class*="content"]', '.article-body', '.post-body'
            ] if 'onefootball.com' in url else
            [
                '.article-content', '.post-content', '.entry-content',
                '[class*="content"]', '.article-body', '.post-body'
            ]
        )

        article_text = ""
        for selector in content_selectors:
            content_div = soup.select_one(selector)
            if content_div:
                for unwanted in content_div.find_all(['script', 'style', 'iframe', 'ads', 'aside']):
                    unwanted.decompose()
                article_text = content_div.get_text(strip=True)
                break

        if not article_text:
            paragraphs = soup.find_all('p')
            article_text = ' '.join(p.get_text(strip=True) for p in paragraphs)

        article_text = ' '.join(article_text.split())
        return article_text[:CONFIG['CONTENT_MAX_LENGTH']]

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç—å–∏ {url}: {e}")
        return ""

def create_basic_summary(article_data: Dict[str, Any]) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AI."""
    content = article_data.get('content', '')
    summary = article_data.get('summary', '')
    title = article_data.get('title', '')

    if content and len(content) > 50:
        sentences = content.split('. ')
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 20][:2]
        if meaningful_sentences:
            result = '. '.join(meaningful_sentences)
            return result + '.' if not result.endswith('.') else result
    return summary or title

def translate_and_format_onefootball(article_data: Dict[str, Any]) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å—é OneFootball –≤ —Å—Ç–∏–ª–µ Football.ua."""
    title = article_data.get('title', '')
    content = article_data.get('content', '')
    summary = article_data.get('summary', '')
    url = article_data.get('url', '')
    
    if not has_gemini_key() or not model:
        logger.warning("Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è OneFootball, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ —Ä–µ–∑—é–º–µ")
        return title  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
    full_text = ""
    if content and len(content) > 50:
        full_text = content
    elif summary and len(summary) > 20:
        full_text = summary
    else:
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        logger.info(f"OneFootball: –∫–æ–Ω—Ç–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π, –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç...")
        full_text = fetch_full_article_content(url) or summary or title
    
    if len(full_text) < 20:
        logger.warning("OneFootball: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return title
    
    logger.info(f"OneFootball: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ - —Å–æ–∑–¥–∞–µ–º –ø–æ—Å—Ç –≤ —Å—Ç–∏–ª–µ Football.ua
    prompt = f"""–¢–∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ñ—É—Ç–±–æ–ª—å–Ω–æ–≥–æ –∫–∞–Ω–∞–ª—É. –ü–µ—Ä–µ–∫–ª–∞–¥–∏ –∞–Ω–≥–ª—ñ–π—Å—å–∫—É –Ω–æ–≤–∏–Ω—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é —Ç–∞ —Å—Ç–≤–æ—Ä–∏ –ø–æ—Å—Ç –¥–ª—è Telegram –≤ —Å—Ç–∏–ª—ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö —Ñ—É—Ç–±–æ–ª—å–Ω–∏—Ö –º–µ–¥—ñ–∞.

–í–ê–ñ–õ–ò–í–û:
- –ü–µ—Ä–µ–∫–ª–∞–¥–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
- –°—Ç–≤–æ—Ä–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å (2-3 —Ä–µ—á–µ–Ω–Ω—è) 
- –ú–∞–∫—Å–∏–º—É–º 150 —Å–ª—ñ–≤
- –°—Ç–∏–ª—å —è–∫ —É Football.ua - –ª–∞–∫–æ–Ω—ñ—á–Ω–æ —Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ
- –ù–ï –∑–≥–∞–¥—É–π OneFootball —É —Ç–µ–∫—Å—Ç—ñ

–ê–Ω–≥–ª—ñ–π—Å—å–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {title}

–ê–Ω–≥–ª—ñ–π—Å—å–∫–∏–π —Ç–µ–∫—Å—Ç: {full_text[:1000]}

–°—Ç–≤–æ—Ä–∏ –¢–Ü–õ–¨–ö–ò –ø–µ—Ä–µ–∫–ª–∞–¥ —É —Ñ–æ—Ä–º–∞—Ç—ñ:
–ó–ê–ì–û–õ–û–í–û–ö –£–ö–†–ê–á–ù–°–¨–ö–û–Æ

–ö–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å –Ω–æ–≤–∏–Ω–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é (2-3 —Ä–µ—á–µ–Ω–Ω—è –∑ –∫–ª—é—á–æ–≤–∏–º–∏ —Ñ–∞–∫—Ç–∞–º–∏)."""

    try:
        response = model.generate_content(prompt)
        translated_result = response.text.strip()
        
        # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —ñ –æ–ø–∏—Å
        lines = translated_result.split('\n')
        translated_title = lines[0].strip()
        
        # –ó–±–∏—Ä–∞—î–º–æ –æ–ø–∏—Å –∑ –Ω–∞—Å—Ç—É–ø–Ω–∏—Ö —Ä—è–¥–∫—ñ–≤
        description_lines = []
        for line in lines[1:]:
            line = line.strip()
            if line and not line.startswith('#'):
                description_lines.append(line)
        
        description = ' '.join(description_lines).strip()
        
        # –Ø–∫—â–æ –æ–ø–∏—Å—É –Ω–µ–º–∞—î, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
        if not description:
            description = translated_title
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ–≤–∂–∏–Ω—É
        if len(description) > CONFIG['TELEGRAM_CAPTION_LIMIT']:
            logger.warning(f"OneFootball: AI –ø–æ–≤–µ—Ä–Ω—É–≤ –∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π —Ç–µ–∫—Å—Ç ({len(description)} —Å–∏–º–≤–æ–ª—ñ–≤), –æ–±—Ä—ñ–∑–∞—î–º–æ")
            sentences = description.split('. ')
            short_result = ""
            for sentence in sentences:
                if len(short_result + sentence + '. ') <= CONFIG['TELEGRAM_CAPTION_LIMIT']:
                    short_result += sentence + '. '
                else:
                    break
            description = short_result.rstrip()
        
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_result = {
            'translated_title': translated_title,
            'translated_content': description
        }
        
        logger.info(f"OneFootball: AI –ø–µ—Ä–µ–∫–ª–∞–≤ –∫–æ–Ω—Ç–µ–Ω—Ç: –∑–∞–≥–æ–ª–æ–≤–æ–∫ {len(translated_title)} —Å–∏–º., –æ–ø–∏—Å {len(description)} —Å–∏–º.")
        return final_result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Gemini –¥–ª—è OneFootball: {e}")
        time.sleep(1)
        # Fallback
        return {'translated_title': title, 'translated_content': title}

def create_enhanced_summary(article_data: Dict[str, Any]) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑—é–º–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gemini –∏–ª–∏ –±–∞–∑–æ–≤–æ–µ —Ä–µ–∑—é–º–µ."""
    source = article_data.get('source', '')
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è OneFootball - –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–ú –≠–¢–û–¢ –ú–ï–¢–û–î
    # –ü–µ—Ä–µ–≤–æ–¥ OneFootball –¥–µ–ª–∞–µ—Ç—Å—è –≤ format_for_social_media
    if source == 'OneFootball':
        return article_data.get('content', '') or article_data.get('summary', '') or article_data.get('title', '')
    
    # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    title = article_data.get('title', '')
    content = article_data.get('content', '')
    summary = article_data.get('summary', '')
    url = article_data.get('url', '')
    
    if not has_gemini_key() or not model:
        return create_basic_summary(article_data)

    # –î–ª—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    if len(content) < 100 and url:
        logger.info(f"–ö–æ–Ω—Ç–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤), –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç...")
        content = fetch_full_article_content(url) or summary or title
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(content)} —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")

    if len(content) < 20:
        logger.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return summary or title

    logger.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –û–±—ã—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    prompt = f"""–¢–∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ñ—É—Ç–±–æ–ª—å–Ω–∏—Ö –Ω–æ–≤–∏–Ω. –°—Ç–≤–æ—Ä–∏ –ö–û–†–û–¢–ö–ò–ô –ø–æ—Å—Ç –¥–ª—è Telegram (–º–∞–∫—Å. {CONFIG['SUMMARY_MAX_WORDS']} —Å–ª—ñ–≤).

–ü—Ä–∞–≤–∏–ª–∞:
- –¢—ñ–ª—å–∫–∏ –∫–ª—é—á–æ–≤—ñ —Ñ–∞–∫—Ç–∏, –±–µ–∑ –ø—Ä–∏–∫—Ä–∞—Å
- –£–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é
- –ú–∞–∫—Å–∏–º—É–º 1-2 —Ä–µ—á–µ–Ω–Ω—è –ø—Ä—è–º–æ—ó –º–æ–≤–∏
- –ù–µ –ø–æ–≤—Ç–æ—Ä—é–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –≥–æ–ª–æ–≤–Ω–∏–π —Ñ–∞–∫—Ç (1-2 —Ä–µ—á–µ–Ω–Ω—è), –¥–µ—Ç–∞–ª—ñ (2-4 —Ä–µ—á–µ–Ω–Ω—è)

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–¢–µ–∫—Å—Ç: {content}

–ö–û–†–û–¢–ö–ò–ô –ü–û–°–¢:"""

    try:
        response = model.generate_content(prompt)
        summary_result = response.text.strip()
        
        if summary_result.lower() == title.lower():
            logger.warning("AI –≤–µ—Ä–Ω—É–ª —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
            return content[:200] + '...' if len(content) > 200 else content
            
        logger.info(f"AI –æ–±—Ä–∞–±–æ—Ç–∞–ª –∫–æ–Ω—Ç–µ–Ω—Ç: {len(summary_result)} —Å–∏–º–≤–æ–ª–æ–≤")
        return summary_result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Gemini: {e}")
        time.sleep(1)
        return content[:200] + '...' if len(content) > 200 else content

def format_for_social_media(article_data: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å—é –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π."""
    title = article_data.get('title', '')
    content = article_data.get('content', '')
    summary = article_data.get('summary', '')
    url = article_data.get('url', '') or article_data.get('link', '')
    source = article_data.get('source', '')

    logger.info(f"–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π [{source}]: {title[:50]}...")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –î–õ–Ø ONEFOOTBALL
    if source == 'OneFootball':
        logger.info("OneFootball: –Ω–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å—Ç–∞—Ç—å—é
        translation_result = translate_and_format_onefootball({
            'title': title,
            'content': content,
            'summary': summary,
            'url': url,
            'source': source
        })
        
        if isinstance(translation_result, dict):
            translated_title = translation_result['translated_title']
            translated_content = translation_result['translated_content']
        else:
            # Fallback –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
            translated_title = title
            translated_content = translation_result or title
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç –≤ —Å—Ç–∏–ª–µ Football.ua
        post = f"<b>‚öΩ {translated_title}</b>\n\n{translated_content}\n\n#—Ñ—É—Ç–±–æ–ª #–Ω–æ–≤–∏–Ω–∏ #—Å–≤—ñ—Ç"
        
        logger.info(f"OneFootball: –≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç: {len(post)} —Å–∏–º–≤–æ–ª–æ–≤")
        return post
    
    # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ
    ai_summary = create_enhanced_summary({
        'title': title, 
        'content': content, 
        'summary': summary,
        'url': url, 
        'source': source, 
        'original_content': article_data.get('original_content', ''),
        'processed_content': article_data.get('processed_content', '')
    })

    # –£–±–∏—Ä–∞–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
    unwanted_prefixes = ["–Ü–Ω—à–µ", "–Ü—Ç–∞–ª—ñ—è", "–Ü—Å–ø–∞–Ω—ñ—è", "–ù—ñ–º–µ—á—á–∏–Ω–∞", "–ß–µ–º–ø—ñ–æ–Ω–∞—Ç", "–°—å–æ–≥–æ–¥–Ω—ñ", "–í—á–µ—Ä–∞"]
    for prefix in unwanted_prefixes:
        if ai_summary.startswith(prefix):
            ai_summary = ai_summary[len(prefix):].strip(": ").lstrip()

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if source == 'ESPN Soccer':
        post = f"<b>üåç {title}</b>\n\n{ai_summary}\n\nüì∞ ESPN Soccer\n#—Ñ—É—Ç–±–æ–ª #–Ω–æ–≤–∏–Ω–∏ #ESPN #—Å–≤—ñ—Ç"
    else:
        post = f"<b>‚öΩ {title}</b>\n\n{ai_summary}\n\n#—Ñ—É—Ç–±–æ–ª #–Ω–æ–≤–∏–Ω–∏ #—Å–ø–æ—Ä—Ç"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç Telegram
    if len(post) > CONFIG['TELEGRAM_MESSAGE_LIMIT']:
        logger.warning(f"–ü–æ—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({len(post)} —Å–∏–º–≤–æ–ª–æ–≤), –æ–±—Ä–µ–∑–∞–µ–º")
        # –û–±—Ä–µ–∑–∞–µ–º ai_summary
        available_space = CONFIG['TELEGRAM_MESSAGE_LIMIT'] - (len(post) - len(ai_summary)) - 50
        if available_space > 100:
            sentences = ai_summary.split('. ')
            short_summary = ""
            for sentence in sentences:
                if len(short_summary + sentence + '. ') <= available_space:
                    short_summary += sentence + '. '
                else:
                    break
            ai_summary = short_summary.rstrip()
            
            # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç
            if source == 'ESPN Soccer':
                post = f"<b>üåç {title}</b>\n\n{ai_summary}\n\nüì∞ ESPN Soccer\n#—Ñ—É—Ç–±–æ–ª #–Ω–æ–≤–∏–Ω–∏ #ESPN #—Å–≤—ñ—Ç"
            else:
                post = f"<b>‚öΩ {title}</b>\n\n{ai_summary}\n\n#—Ñ—É—Ç–±–æ–ª #–Ω–æ–≤–∏–Ω–∏ #—Å–ø–æ—Ä—Ç"
    
    logger.info(f"–ì–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç [{source}]: {len(post)} —Å–∏–º–≤–æ–ª–æ–≤")
    return post

def download_image(image_url: str, filename: str = None) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL."""
    if not image_url:
        return ""
    try:
        images_dir = "images"
        os.makedirs(images_dir, exist_ok=True)
        if not filename:
            parsed_url = urlparse(image_url)
            filename = os.path.basename(parsed_url.path) or f"image_{hash(image_url) % 10000}.jpg"
        filepath = os.path.join(images_dir, filename)

        headers = {
            "User-Agent": random.choice(CONFIG['USER_AGENTS']),
            **({"Referer": "https://www.espn.com/", "Accept": "image/webp,image/apng,image/*,*/*;q=0.8"}
               if 'espn.com' in image_url else 
               {"Referer": "https://onefootball.com/", "Accept": "image/webp,image/apng,image/*,*/*;q=0.8"}
               if 'onefootball.com' in image_url else {})
        }
        response = requests.get(image_url, headers=headers, timeout=10)
        response.raise_for_status()
        with open(filepath, 'wb') as f:
            f.write(response.content)
        logger.info(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {filepath}")
        return filepath
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_url}: {e}")
        return ""

def process_article_for_posting(article_data: Dict[str, Any]) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—å—é –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏."""
    source = article_data.get('source', 'Unknown')
    logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å—é [{source}]: {article_data.get('title', '')[:50]}...")
    
    post_text = format_for_social_media(article_data)
    image_path = download_image(article_data.get('image_url', ''))

    result = {
        'title': article_data.get('title', ''),
        'post_text': post_text,
        'image_path': image_path,
        'image_url': article_data.get('image_url', ''),
        'url': article_data.get('url', '') or article_data.get('link', ''),
        'summary': article_data.get('summary', ''),
        'source': source,
        **(
            {
                'original_title': article_data.get('original_title', ''),
                'original_content': article_data.get('original_content', ''),
                'processed_content': article_data.get('processed_content', '')
            }
            if source in ['ESPN Soccer', 'OneFootball'] else {}
        )
    }
    logger.info(f"–°—Ç–∞—Ç—å—è [{source}] –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    return result

# –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º
def summarize_news(title: str, url: str, content: str = '') -> str:
    return create_enhanced_summary({'title': title, 'url': url, 'content': content, 'summary': title})

def simple_summarize(title: str, url: str) -> str:
    return f"üî∏ {title}"
