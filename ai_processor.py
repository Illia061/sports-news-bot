import os
import requests
from typing import Dict, Any
from urllib.parse import urlparse
import google.generativeai as genai
import time
from bs4 import BeautifulSoup

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_AVAILABLE = False
model = None

def init_gemini():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞ Gemini"""
    global GEMINI_AVAILABLE, model
    if not GEMINI_API_KEY:
        print("‚ö†Ô∏è GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω - AI —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        return
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-2.5-flash")
        GEMINI_AVAILABLE = True
        print("‚úÖ Gemini –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini: {e}")

def has_gemini_key() -> bool:
    if not GEMINI_AVAILABLE:
        init_gemini()
    return GEMINI_AVAILABLE

def fetch_full_article_content(url: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ URL"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–∞—Ç—å–∏ (–∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É football.ua)
        content_selectors = [
            '.article-content',
            '.post-content', 
            '.entry-content',
            '[class*="content"]',
            '.article-body',
            '.post-body'
        ]
        
        article_text = ""
        for selector in content_selectors:
            content_div = soup.select_one(selector)
            if content_div:
                # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                for unwanted in content_div.find_all(['script', 'style', 'iframe', 'ads']):
                    unwanted.decompose()
                
                article_text = content_div.get_text(strip=True)
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –±–µ—Ä–µ–º –≤—Å–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        if not article_text:
            paragraphs = soup.find_all('p')
            article_text = ' '.join([p.get_text(strip=True) for p in paragraphs])
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        article_text = ' '.join(article_text.split())  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        
        return article_text[:2000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è AI
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏: {e}")
        return ""

def create_enhanced_summary(article_data: Dict[str, Any]) -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ —á–µ—Ä–µ–∑ Gemini"""
    if not has_gemini_key() or not model:
        # –ï—Å–ª–∏ –Ω–µ—Ç AI, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Ä–µ–∑—é–º–µ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content = article_data.get('content', '')
        summary = article_data.get('summary', '')
        title = article_data.get('title', '')
        
        if content and len(content) > 50:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            sentences = content.split('. ')
            meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
            if meaningful_sentences:
                result = '. '.join(meaningful_sentences[:2])
                if not result.endswith('.'):
                    result += '.'
                return result
        
        return summary or title

    title = article_data.get('title', '')
    content = article_data.get('content', '')
    summary = article_data.get('summary', '')
    url = article_data.get('url', '')
    
    # –ì–õ–ê–í–ù–ê–Ø –ü–†–û–ë–õ–ï–ú–ê –ë–´–õ–ê –ó–î–ï–°–¨: –µ—Å–ª–∏ content –ø—É—Å—Ç–æ–π, –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –µ–≥–æ
    if not content or len(content) < 100:
        print(f"üîÑ –ö–æ–Ω—Ç–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤), –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç...")
        if url:
            full_content = fetch_full_article_content(url)
            if full_content:
                content = full_content
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º summary")
                content = summary or title
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if not content or len(content) < 20:
        print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è AI –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return summary or title

    print(f"ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini {len(content)} —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")

    prompt = f"""–¢–∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ñ—É—Ç–±–æ–ª—å–Ω–∏—Ö –Ω–æ–≤–∏–Ω.
–ü–µ—Ä–µ—Ñ—Ä–∞–∑—É–π —ñ —Å—Ç–≤–æ—Ä–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∏–π –≤–∏–∫–ª–∞–¥ —Ü—ñ—î—ó —Ñ—É—Ç–±–æ–ª—å–Ω–æ—ó –Ω–æ–≤–∏–Ω–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.

–í–∏–º–æ–≥–∏:
- –ó—Ä–æ–∑—É–º—ñ–ª–æ —Ç–∞ —Ü—ñ–∫–∞–≤–æ
- –ó–±–µ—Ä–µ–∂–∏ –≤—Å—ñ –≤–∞–∂–ª–∏–≤—ñ —Ñ–∞–∫—Ç–∏
- –£–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é
- –ë–µ–∑ –∑–∞–π–≤–∏—Ö –¥–µ—Ç–∞–ª–µ–π
- –Ø–∫—â–æ —î —Ä–µ–π—Ç–∏–Ω–≥ ‚Äî –ø—É–±–ª—ñ–∫—É–π –ø–æ–≤–Ω—ñ—Å—Ç—é
- –Ø–∫—â–æ —î –ø—Ä—è–º–∞ –º–æ–≤–∞ ‚Äî –≤–∏–∫–ª–∞–¥–∏ —ó—ó –∫–æ—Ä–æ—Ç–∫–æ –Ω–∞ 3‚Äì4 —Ä–µ—á–µ–Ω–Ω—è
- –ú–∞–∫—Å–∏–º—É–º 200-250 —Å–ª—ñ–≤

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–¢–µ–∫—Å—Ç: {content}

–°—Ç–∏—Å–ª–∏–π –≤–∏–∫–ª–∞–¥:
"""
    try:
        response = model.generate_content(prompt)
        summary_result = response.text.strip()
        
        # Ensure summary isn't just the title
        if summary_result.lower() == title.lower():
            print("‚ö†Ô∏è AI –≤–µ—Ä–Ω—É–ª —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
            return content[:200] + '...' if len(content) > 200 else content
        
        print(f"‚úÖ AI –æ–±—Ä–∞–±–æ—Ç–∞–ª –∫–æ–Ω—Ç–µ–Ω—Ç: {len(summary_result)} —Å–∏–º–≤–æ–ª–æ–≤")
        return summary_result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Gemini: {e}")
        time.sleep(1)  # Small delay to prevent rate limiting
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞–∫ fallback
        return content[:200] + '...' if len(content) > 200 else content

def format_for_social_media(article_data: Dict[str, Any]) -> str:
    title = article_data.get('title', '')
    content = article_data.get('content', '')
    summary = article_data.get('summary', '')
    url = article_data.get('url', '') or article_data.get('link', '')

    print(f"üìù –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π: {title[:50]}...")
    print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   Summary: {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤")

    if has_gemini_key():
        print("ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ...")
        ai_summary = create_enhanced_summary({
            'title': title,
            'content': content,
            'summary': summary,
            'url': url
        })
    else:
        print("üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ —Ä–µ–∑—é–º–µ...")
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ AI
        if content and len(content) > 50:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            sentences = content.split('. ')
            meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
            if meaningful_sentences:
                ai_summary = '. '.join(meaningful_sentences[:2])
                if not ai_summary.endswith('.'):
                    ai_summary += '.'
            else:
                ai_summary = content[:200] + '...' if len(content) > 200 else content
        else:
            ai_summary = summary or content[:200] + '...' if len(content) > 200 else content

    # Remove unwanted prefixes
    unwanted_prefixes = ["–Ü–Ω—à–µ", "–Ü—Ç–∞–ª—ñ—è", "–Ü—Å–ø–∞–Ω—ñ—è", "–ù—ñ–º–µ—á—á–∏–Ω–∞", "–ß–µ–º–ø—ñ–æ–Ω–∞—Ç", "–°—å–æ–≥–æ–¥–Ω—ñ", "–í—á–µ—Ä–∞"]
    for prefix in unwanted_prefixes:
        if ai_summary.startswith(prefix):
            ai_summary = ai_summary[len(prefix):].strip(": ").lstrip()

    post = f"<b>‚öΩ {title}</b>\n\n"
    if ai_summary and ai_summary != title:
        post += f"{ai_summary}\n\n"

    post += "#—Ñ—É—Ç–±–æ–ª #–Ω–æ–≤–∏–Ω–∏ #—Å–ø–æ—Ä—Ç"
    
    print(f"‚úÖ –ì–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç: {len(post)} —Å–∏–º–≤–æ–ª–æ–≤")
    return post

def download_image(image_url: str, filename: str = None) -> str:
    try:
        if not image_url:
            return ""
        images_dir = "images"
        os.makedirs(images_dir, exist_ok=True)
        if not filename:
            parsed_url = urlparse(image_url)
            filename = os.path.basename(parsed_url.path)
            if not filename or '.' not in filename:
                filename = f"image_{hash(image_url) % 10000}.jpg"
        filepath = os.path.join(images_dir, filename)
        response = requests.get(image_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        response.raise_for_status()
        with open(filepath, 'wb') as f:
            f.write(response.content)
        return filepath
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return ""

def process_article_for_posting(article_data: Dict[str, Any]) -> Dict[str, Any]:
    print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å—é: {article_data.get('title', '')[:50]}...")
    
    post_text = format_for_social_media(article_data)
    image_path = download_image(article_data['image_url']) if article_data.get('image_url') else ""
    
    result = {
        'title': article_data.get('title', ''),
        'post_text': post_text,
        'image_path': image_path,
        'image_url': article_data.get('image_url', ''),
        'url': article_data.get('url', '') or article_data.get('link', ''),
        'summary': article_data.get('summary', '')
    }
    
    print(f"‚úÖ –°—Ç–∞—Ç—å—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    return result

# Old compatible interfaces
def summarize_news(title: str, url: str, content: str = '') -> str:
    article_data = {'title': title, 'url': url, 'content': content, 'summary': title}
    return create_enhanced_summary(article_data) if has_gemini_key() else f"üî∏ {title}"

def simple_summarize(title: str, url: str) -> str:
    return f"üî∏ {title}"
